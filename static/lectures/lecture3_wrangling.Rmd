---
title: "ETC1010: Data Modelling and Computing"
subtitle: 'Lecture 3: Wrangling your data'
author: "Di Cook (dicook@monash.edu, @visnut)"
date: "Week 3"
output:
  xaringan::moon_reader:
    css: ["default", "myremark.css"]
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, echo = FALSE, warning = FALSE, message=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  echo=FALSE,
  comment = "",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE
)
library(tidyverse)
library(gridExtra)
library(plotly)
library(ggthemes)
library(ggmap)
```

# Overview

- Data structures, variable types
- Wrangling verbs: filter, arrange, select, mutate, summarise
- Making joins
- Working with dates

---
# Data structures

- Data frames
- Matrices/vectors
- Lists
- Tibbles

---
# data.frame/tibble vs matrices/vectors

Mostly what we have seen so far are data.frame or tibble

- Rectangular format
- Each column might be a different type of variable
- Each column is same length

Matrices/vectors

- Original data format
- All columns have numerical values

---
# Lists

- Not necessarily rectangular
- Anything can be packed into a list
- We will see more of these when we fit models, because model summaries are typically shared as a list
- Trickier to work with

---
# How do you know what you have?

```{r echo=TRUE}
genes <- read_csv("data/genes.csv")
genes
is_tibble(genes)
is.data.frame(genes)
is.matrix(genes)
is.list(genes)
```

---

```{r echo=TRUE}
melbtemp <- read.fwf("data/ASN00086282.dly", 
   c(11, 4, 2, 4, rep(c(5, 1, 1, 1), 31)), fill=T)
head(melbtemp[,c(1,2,3,4,seq(5,100,4))])
is_tibble(melbtemp)
is.data.frame(melbtemp)
is.matrix(melbtemp)
is.list(melbtemp)
```

---
# Variable types

- `int` integer.
- `dbl` doubles, or real numbers
- `num` numeric, includes integer or double
- `chr` characters, or strings
- `lgl` or `logi` logical, true or false
- `fctr` or `Factor` fancy character, contains additional information about levels and labels
- `date` and `dttm` time and date structures

---
# Converting formats

```{r echo=TRUE}
melbtemp <- melbtemp[,c(1,2,3,4,seq(5,128,4))]
colnames(melbtemp) <- c("id", "year", "month", "var", paste0("V",1:31))
melbtemp <- melbtemp %>% 
  gather(day, value, V1:V31) %>%
  mutate(day = sub("V", "", day)) %>%
  mutate(value=ifelse(value==-9999, NA, value)) %>%
  filter(var %in% c("PRCP", "TMAX", "TMIN")) %>%
  spread(var, value) %>%
  mutate(PRCP=PRCP/10, TMAX=TMAX/10, TMIN=TMIN/10) %>%
  as_tibble()
melbtemp
```

---
# Filter

Pick observations by their values. For example, 

```
filter(var %in% c("PRCP", "TMAX", "TMIN"))
```

took the column named `var` and keeps rows that have one of three values `PRCP`, `TMAX`, `TMIN`. All other rows are removed. 

---
# Logical operators

- Comparisons 
    - `<`, `<=`: less than, less than or equal
    - `>`, `>=`: greater than, greater than or equal
    - `==`, `!=`: equal to, not equal to
    - Cautions: computers have a hard time with equals, `near()` is a function that can be useful for real numbers, will check within a small neighbourhood of a value
- Logicals
    - `&` and, both checks have to be true
    - `|` or, either check is true
    - `%in%` checks the elements of a collection, multiple or's
- Missings: `is.na()`    

---
# Arrange

Orders a data frame or tibble by the values in one column

```{r echo=TRUE}
library(lubridate)
melbtemp %>% 
  mutate(date=ymd(paste(year, month, day, sep="-"))) %>%
  arrange(date)
```

---
# Select

Choose some of the __variables__.

```{r echo=TRUE}
airport <- read_csv("data/airports.csv")
airport
```

---

```{r echo=TRUE}
airport %>%
  select(AIRPORT, LATITUDE, LONGITUDE, AIRPORT_IS_LATEST, DISPLAY_AIRPORT_NAME)
```

---
# Mutate

Create new, or transform existing, variables, e.g. for the Melbourne temperature data, we put the temperature and precipitation values into Celsius and mm, byt dividing by 10.

```
mutate(PRCP=PRCP/10, TMAX=TMAX/10, TMIN=TMIN/10)
```

---
# Arithmetic

- Typical calculations: `+`, `-`, `*`, `/`; `^` (power)
- Modular:
    - `%/%` integer division
    - `%%` remainder
- Transformations: `log()`, `log10()`, `sqrt()`
- Temporal: `lead()`, `lag()` create variables which are temporal lags of existing
- Stats: `rank()`, `cumsum()`

---
# Summarise

Calculate a quantity on a column, producing a single number, e.g. for the audio data:

```
summarise(m = mean(value), s = sd(value), 
            mx = max(value), mn = min(value))
```

- Stats: `mean()`, `median()`, `sd()`, `min()`, `max()`, `sum()`
- Rounding: `floor()`, `ceiling()`, `trunc()`, `round()`, `signif()`

---
# Grouping and ungrouping

Summarise is most commonly called on subgroups of data. We might want to calculate means and standard deviation across genders, or countries or schools. For the audio data, we calculated the summary statistics by the word spoken:

```
  group_by(word) %>%
  summarise(m = mean(value), s = sd(value), 
            mx = max(value), mn = min(value))
```

If we want to more operations on the variable `word` after these calculations, you would need to do an `ungroup()` step.

---
# Counts and tallies

Dealing with categorical data, means wanting to count or tally. The function `count()` allows calculate the number of objects in levels of a variable, and the function `tally()` calculates how many objects there are. We used `count()` for the tweets example:

```
tweets %>%
  count(source, hour = hour(with_tz(created, "EST")))
```

to calculate the number of tweets from the different devices, android or iphone, each hour. 


---
# Putting it together for the french fries

10 week sensory experiment, 12 individuals assessed taste of french fries on several scales (how potato-y, buttery, grassy, rancid, paint-y do they taste?), fried in one of 3 different oils, replicated twice. First few rows:

```{r, echo=FALSE}
data(french_fries, package = "reshape2")
french_fries <- as_tibble(french_fries)
french_fries
```

---
# What would we like to know?

- Is the design complete?
- Are replicates like each other?
- How do the ratings on the different criteria differ?
- Are raters giving different scores on average?
- Do ratings change over the weeks?

Each of these questions involves different summaries of the data.

---
# Answer some Questions

- Easiest question is whether the ratings are similar on the different scales, potato'y, buttery, grassy, rancid and painty. 
- We need to gather the data into long form, and make plots facetted by the scale. 

```{r echo=TRUE, fig.height=2.6}
ff.m <- french_fries %>% 
  gather(type, rating, -subject, -time, -treatment, -rep)
ggplot(data=ff.m, aes(x=rating)) + geom_histogram(binwidth=2) + 
  facet_wrap(~type, ncol=5) 
```

---
# Look at it a different way

```{r fig.width=8, fig.height=5}
ggplot(data=ff.m, aes(x=type, y=rating, fill=type)) + 
  geom_boxplot()
```

---
# Comparison of the distributions of criteria

Ratings on the different criteria are quite different. 
- Potato'y scores relatively highly. 
- Grassy are mostly 0's
- Buttery and painty are skewed right, mostly low values a few high ratings
- Rancid is quite varied, we would hope that this relates to time, that the chips get more rancid as the weeks go by.

---
# Do the replicates look like each other?

- We will start to tackle this by plotting the replicates against each other using a scatterplot. 
- If raters give the same rating to the replicates, we would expect something close to this, then all values would lie on the X=Y line
- We need to 
    - gather the data into long form, and 
    - then get the replicates spread into separate columns. 

---

```{r echo=TRUE}
ff.s <- ff.m %>% spread(rep, rating)
head(ff.s)
```

---
# Check Replicates

```{r, fig.show='hold', fig.align='default', fig.height=4, fig.width=4}
ggplot(data=ff.s, aes(x=`1`, y=`2`)) + geom_point() +
  theme(aspect.ratio=1) + xlab("Rep 1") + ylab("Rep 2")
ggplot(data=ff.s, aes(x=`1`, y=`2`)) + geom_point() +
  theme(aspect.ratio=1) + xlab("Rep 1") + ylab("Rep 2") + 
  scale_x_sqrt() + scale_y_sqrt()
```

They have some positive linear association, but there is a lot more variation than expected. One rep might have scored 15 and the other 0, that's the same batches, same oil, same criteria, same week, same rater!

---
# Separately by criteria ...


```{r echo=FALSE, fig.width=10, fig.height=4}
ggplot(data=ff.s, aes(x=`1`, y=`2`)) + geom_point() +
  theme(aspect.ratio=1) + 
  xlab("Rep 1") + ylab("Rep 2") + facet_wrap(~type, ncol=5)
```

buttery and potato'y look a bit better. The rest are still terrible. 

---
# by oil ...

```{r, echo=FALSE, fig.width=10, fig.height=6}
ggplot(data=ff.s, aes(x=`1`, y=`2`)) + geom_point() +
  theme(aspect.ratio=1) + 
  xlab("Rep 1") + ylab("Rep 2") + facet_grid(treatment~type)
```

Not much improvement here.

---
# By subject ...

```{r, echo=FALSE, fig.width=10, fig.height=6}
ggplot(data=ff.s, aes(x=`1`, y=`2`)) + geom_point() +
  theme(aspect.ratio=1) + 
  xlab("Rep 1") + ylab("Rep 2") + facet_wrap(~subject, ncol=4)
```

Some subjects may be more experienced than others?

---


Because the replicates do not look like each other, the quality of the data might be questioned at this point. 

Nevertheless, lets push on with some of the other questions.

---
# Completeness of experimental design

If the data is complete it should be 12 x 10 x 3 x 2, that is, 6 records for each person. (Assuming that each person rated on all scales.) 

To check this we want to tabulate the number of records for each subject, time and treatment. That is,
- select appropriate columns, 
- tabulate, 
- count and 
- spread it out to give a nice table.

---

```{r echo=TRUE}
french_fries %>% 
  select(subject, time, treatment) %>% 
  count(subject, time) %>%
  spread(time, n)
```

Its pretty good, but subjects, 3, 31, 79, 86 all missed a rating session. 

---
# By criteria

```{r}
ff.m %>% 
  select(subject, time, treatment, type) %>% 
  count(subject, time) %>%
  spread(time, n)
```

---
# Change in rancid ratings over weeks

- Filter on criteria
- Compute means by subject, week and oil

```{r echo=TRUE}
ff.av <- ff.m %>% 
  filter(type == "rancid") %>%
  group_by(subject, time, treatment) %>%
  summarise(rating=mean(rating))
```

---

```{r fig.width=10, fig.height=6}
p <- ff.m %>% filter(type == "rancid") %>%
  ggplot(aes(x=time, y=rating, colour=treatment)) + 
         geom_point(alpha=0.5) +
  facet_wrap(~subject) 
p + geom_line(data=ff.av, aes(group=treatment))
```

Oh, its awful data! Only subject 86 is seeing the chips get more rancid over time, with maybe oil 1 being worse. Subject 63, shows some trend. Nothing is rancid for subjects 78, 79. Subject 53 thinks they taste better after many weeks in the same old oil!

---
# Joins

It’s rare that a data analysis involves only a single table of data. Typically you have many tables of data, and you must combine them to answer the questions that you’re interested in. Collectively, multiple tables of data are called relational data because it is the relations, not just the individual datasets, that are important.

---

```{r echo=TRUE}
load("data/plane_N4YRAA.rda")
plane_N4YRAA %>% glimpse()
```


```{r echo=TRUE}
airport <- read_csv("data/airports.csv")
airport %>% select(AIRPORT, LATITUDE, LONGITUDE, AIRPORT_STATE_NAME) %>%
  glimpse()
```

---
# Joining the two tables

- Purpose is to show flight movement on the map
- Key is the airport three letter code, 
    - called ORIGIN or DEST in plane_N4YRAA table
    - called AIRPORT in the airport table
- One table, plane_N4YRAA, has less airports than the other
    - Only want to keep the rows of airport table, for those that appear in the plane_N4YRAA table


---

```{r echo=TRUE}
airport <- airport %>%
  select(AIRPORT, LATITUDE, LONGITUDE, AIRPORT_IS_LATEST, DISPLAY_AIRPORT_NAME) %>%
  filter(AIRPORT_IS_LATEST == 1) %>%
  select(-AIRPORT_IS_LATEST)

N4YRAA_latlon <- left_join(plane_N4YRAA, airport,
                           by = c("ORIGIN"="AIRPORT")) %>%
  rename("ORIGIN_LATITUDE"="LATITUDE",
         "ORIGIN_LONGITUDE"="LONGITUDE")
N4YRAA_latlon %>% 
  select(ORIGIN, ORIGIN_LATITUDE, ORIGIN_LONGITUDE, 
         DISPLAY_AIRPORT_NAME)
```

The variables ORIGIN_LATITUDE, ORIGIN_LONGITUDE, DISPLAY_AIRPORT_NAME are added to corresponding row in the plane_N4YRAA table.

---

- Added the spatial coordinates (lat, lon) for the origin airport
- The same needs to be done for the destination airport
- Then the airports can be drawn over a map

```{r}
N4YRAA_latlon <- left_join(N4YRAA_latlon, airport,
                           by = c("DEST"="AIRPORT")) %>%
  rename("DEST_LATITUDE"="LATITUDE",
         "DEST_LONGITUDE"="LONGITUDE")

N4YRAA_latlon <- N4YRAA_latlon %>% arrange(FL_DATE, DEP_TIME)

map <- get_map(c(lon=-92.20562, lat=36.20259), zoom=5)
ggmap(map) +
  geom_segment(data=filter(N4YRAA_latlon,
                           FL_DATE == ymd("2017-05-06")),
               aes(x=ORIGIN_LONGITUDE, xend=DEST_LONGITUDE,
                   y=ORIGIN_LATITUDE, yend=DEST_LATITUDE),
               color="navyblue") +
  geom_point(data=filter(N4YRAA_latlon,
                         FL_DATE == ymd("2017-05-06")),
             aes(x=ORIGIN_LONGITUDE,
                 y=ORIGIN_LATITUDE), color="orange",
             alpha=0.3, size=3) +
  geom_point(data=filter(N4YRAA_latlon,
                         FL_DATE == ymd("2017-05-06")),
             aes(x=DEST_LONGITUDE,
                 y=DEST_LATITUDE), color="red",
             alpha=0.3, size=1) +
   theme_map()
```
---
class: inverse middle 
# Share and share alike

<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

