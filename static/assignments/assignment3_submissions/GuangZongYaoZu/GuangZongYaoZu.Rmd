---
title: "GuangZongYaoZu"
author: "Shibo Dong, Ronghao Zhang, Linguo Yang, Ziqi Hao"
date: "22 April 2018"
output: html_document
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  collapse = TRUE,
  comment = "",
  cache = FALSE
)
```

## Extract and tidy the data

```{r}
library(tidyverse)
library(broom)

library(naniar)
houses <- read_csv("~/R/data/Melbourne_housing_FULL.csv")

houses <- houses %>%
  select(Price, Rooms, Type, Distance, Bedroom2, Bathroom)

library(visdat)
vis_dat(houses)
```

It can be seen that the missing values contribute a large proportion of data. If we directly drop all the missing value, the analysis will be significantly influenced. We need to impute these missing values to do most analyses.

```{r}
ggplot(houses,
         aes(x = Rooms,
             y = Bedroom2)) +
  facet_wrap(~Type) +
  scale_color_brewer(palette="Dark2") +
  geom_miss_point() + theme(aspect.ratio = 1)
```

There is an obvious relationship between rooms and bedrooms, so the imputation should take account of the linear relationship between rooms and bedrooms.

```{r}
tidy1 <- houses %>% filter(!is.na(Price))

tidy1 <- bind_shadow(tidy1)

br_lm <- lm(Bedroom2~Rooms, data=tidy1)
ba_lm <- lm(Bathroom~Rooms, data=tidy1)

tidy1 <- tidy1 %>%
  mutate(Bathroom = ifelse(is.na(Bathroom),
                        predict(ba_lm, .),
                        Bathroom)) %>%
  mutate(Bedroom2 = ifelse(is.na(Bedroom2),
                        predict(br_lm, .),
                        Bedroom2))  

ggplot(tidy1,
         aes(x = Rooms,
             y = Bedroom2)) +
  facet_wrap(~Type) +
  scale_color_brewer(palette="Dark2") +
  geom_miss_point() + theme(aspect.ratio = 1)
```

```{r}
houses_tidy <- tidy1 %>%
  select(Price,Rooms,Type,Distance,Bedroom2,Bathroom) %>%
  mutate(Price = as.numeric(Price),
         Rooms = as.numeric(Rooms),
         Bedroom2 = as.numeric(Bedroom2),
         Bathroom = as.numeric(Bathroom)) %>%
  mutate(Type = factor(Type, ordered=FALSE)) %>%
  mutate(Price_million = Price/1000000)
```

Because The distribution of property price is right-skewed, we would better to transform it to log10 scale.

```{r}
ggplot(houses_tidy,
       aes(x=Price_million)) +
  geom_bar(stat = 'density') +
  ggtitle("The distribution of property price")

houses_tidy <- houses_tidy %>%
  mutate(Price_million = log10(Price_million))

head(houses_tidy)
```

So the final tidy data still has 27247, which is not significantly different from original data.

## Plot the data

```{r}
ggplot(houses_tidy, aes(x=Rooms, y=Price_million,
                            colour=Type)) + 
  geom_point(alpha=0.3) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~Type) +
  geom_smooth(method="lm", se=FALSE)
```

Apparently, There is an linear relationship between the number of rooms and Price per million in all three type of property.

## Modelling

```{r}
mod1 <- lm(Price_million ~ Rooms*Type, data = houses_tidy)
tidy(mod1)
```

we can assume that Model 1 has an interaction. This means that the slope will be allowed to vary for the different levels of the categorical variable, Type.

```{r}
hou_mod1 <- augment(mod1, houses_tidy)
ggplot(houses_tidy, aes(x=Rooms, y=Price_million,
                        colour=Type)) + 
  geom_point(alpha=0.3) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~Type,scales = "free_x") +
  geom_line(data = hou_mod1, aes(y=.fitted)) +
  ggtitle("Model 1")
```

```{r}
ggplot(hou_mod1, aes(x=Rooms, y=.fitted,
                           colour=Type)) +
  geom_line() +
  scale_colour_brewer("Type", palette="Dark2") +
  ggtitle("Model 1")
```

It also verified our assumption, which indicates an interaction between the number of rooms and types of property.

```{r}
glance(mod1)
```

The r.squared is much lower than expected. What we need to do is add one more variable into the model and compare which model is better to use.


```{r}
mod2 <- lm(Price_million ~ Rooms*Type+Distance, data = houses_tidy)
tidy(mod2)
```

```{r}
hou_mod2 <- augment(mod2, houses_tidy)
ggplot(houses_tidy, aes(x=Rooms, y=Price_million,
                        colour=Type)) + 
  geom_point(alpha=0.3) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~Type,scales = "free_x") +
  geom_line(data = hou_mod2, aes(y=.fitted)) +
  ggtitle("Model 2")
```

```{r}
ggplot(hou_mod2, aes(x=Rooms, y=.fitted,
                           colour=Type)) +
  geom_line() +
  scale_colour_brewer("Type", palette="Dark2") +
  ggtitle("Model 2")
```

```{r}
glance(mod2)
```

The r.squared for model 2 is much higher and its deviance is kind of smaller than model 1. Thus, model 2 is more reasonable and better for prediction.


## Diagnostic

```{r}
library(gridExtra)
p1 <- ggplot(hou_mod1, aes(x=.fitted, y=.std.resid,
                           color="Red")) +
  geom_point(alpha=0.3) + 
  ggtitle("Model 1")
p2 <- ggplot(hou_mod2, aes(x=.fitted, y=.std.resid,
                           color="Red")) +
  geom_point(alpha=0.3) + 
  ggtitle("Model 2")
grid.arrange(p1, p2, ncol=2)
```

It is obvious that model 1 residuals are widespread, yet model 2 residuals are much closer to 0. Consequently, the model 2 is more precise.
In addition, the p-value suggests whether the variable is important for analysis. In model 2, town houses might not be important, since it would be similar to houses. And the value Rooms:Typeu is unreasonably large, as the location might be the significant factor influencing the unit price rather than the number of rooms.





