---
title: "ETC 1010 Assignment 4"
author: "Di Cook"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  collapse = TRUE,
  comment = "",
  fig.height = 8,
  fig.width = 12,
  fig.align = "center",
  cache = FALSE
)
```

# Instructions

- This is a team assignment. 
- You need to write a report with answers to each of the questions. 
- Turn in the `html` output file, and also the `Rmd` file. 
- Total points for the assignment is 20. Five points of the score from the assignment will be given by another team, who will give you full marks if they can compile your report, and get the same answers as you, and find your explanations of the plots understandable and informative. Five points will be for individual effort. And the remaining 10 points will be the final group report.

# Exercise

*[Melbourne property prices have taken their biggest hit since 2012, falling by almost 2 per cent in the past three months](https://www.domain.com.au/news/melbourne-median-house-price-falls-to-882082-over-june-quarter-domain-group-report-20180726-h134ao-754199/)* Jim Malo, Jul 26 2018, Domain

This assignment explores the data provided on [Melbourne house prices by Anthony Pino](https://www.kaggle.com/anthonypino/melbourne-housing-market). The goal is to examine whether housing prices have cooled in Melbourne, and help Anthony decide whether it is time to buy a two bedroom apartment in Northcote. 

## Your tasks

1. Make a map of Melbourne showing the locations of the properties. 

```{r echo=FALSE}
library(tidyverse)
library(lubridate)
mh <- read_csv("data/Melbourne_housing_FULL.csv") %>%
  rename(lon=Longtitude, lat=Lattitude) %>%
  mutate(Date = dmy(Date))
library(ggmap)
map <- get_map(location = c(145.0, -37.8), zoom=10)
ggmap(map) + geom_point(data=mh, aes(x=lon, y=lat), colour="orange", size=0.5, alpha=0.5)
```

2. Filter the data to focus only on the records for Northcote units. Make a plot of Price by Date, facetted by number of bedrooms. The main thing to learn from this plot is that there are many missing values for number of bedrooms. Impute the missing values, based on the regression method (covered in class). Make sure your predicted value is an integer. Re-make the plot of Price by Date, facetted by number of bedrooms. Make a description of what you learn from the plot, particularly about the trend of 2 bedroom unit prices in Northcote.

```{r echo=FALSE}
nc <- mh %>% filter(Suburb == "Northcote", Type == "u")
ggplot(nc, aes(x=Date, y=Price)) + 
  geom_point() + geom_smooth(se=F) +
  facet_wrap(~Bedroom2, ncol=4) 
library(naniar)
nc_ms <- nc %>% bind_shadow()
br2 <- lm(Bedroom2~Rooms, data=nc_ms)
nc_ms <- nc_ms %>%
  mutate(Bedroom2=ifelse(is.na(Bedroom2),
    round(predict(br2, new=nc_ms), 0), Bedroom2))
ggplot(nc_ms, aes(x=Date, y=Price)) + 
  geom_point() + geom_smooth(se=F) +
  facet_wrap(~Bedroom2, ncol=4) 
```

3. Using the many models approach, fit a linear model for Price on Date, separately for every suburb, for 2 bedroom units. You will need to impute the Bedroom2 variable, in the same way done in the previous question. Collect the model estimates, and also the model fit statistics. What suburb has had the largest increase, which has had the biggest decrease in prices? Which suburbs have the worst fitting models?

```{r echo=FALSE}
mh_ms <- mh %>% bind_shadow()
br2 <- lm(Bedroom2~Rooms, data=mh_ms)
mh_ms <- mh_ms %>%
  mutate(Bedroom2=ifelse(is.na(Bedroom2),
    round(predict(br2, new=mh_ms), 0), Bedroom2))

mh_ms %>% filter(Type == "u", Bedroom2 == 2) %>% count(Suburb, sort = TRUE) %>% ggplot(aes(x=n)) + geom_histogram()
keep <- mh_ms %>% filter(Type == "u", Bedroom2 == 2) %>% 
  count(Suburb, sort = TRUE) %>%
  filter(n > 30)
mh_u <- mh_ms %>% filter(Suburb %in% keep$Suburb) %>%
  mutate(days = as.numeric(Date - ymd("2016-01-28")))
library(purrr)
by_suburb <- mh_u %>% 
  select(Suburb, Date, Price, days) %>%
  group_by(Suburb) %>% 
  nest()
by_suburb <- by_suburb %>% 
  mutate(
    model = purrr::map(data, ~ lm(Price ~ days, 
                                  data = .))
  )
suburb_coefs <- by_suburb %>% 
  unnest(model %>% purrr::map(broom::tidy))
suburb_coefs <- suburb_coefs %>% 
  select(Suburb, term, estimate) %>% 
  spread(term, estimate) %>%
  rename(intercept = `(Intercept)`)
head(suburb_coefs)
p <- ggplot(suburb_coefs, aes(x=intercept, y=days, 
                          label=Suburb)) +
  geom_point(alpha=0.5, size=2) 
library(plotly)
ggplotly(p)
suburb_fit <- by_suburb %>% 
  unnest(model %>% 
           purrr::map(broom::glance))
ggplot(suburb_fit, aes(x=r.squared)) + geom_histogram()
bestfit <- suburb_fit %>% filter(r.squared > 0.08)
mh_u_sub <- mh_u %>% filter(Suburb %in% bestfit$Suburb)
ggplot(data=mh_u_sub, aes(x=Date, y=Price)) + 
         geom_point() + geom_smooth(method="lm", se=FALSE)
worstfit <- suburb_fit %>% filter(r.squared < 0.001)
mh_u_sub <- mh_u %>% filter(Suburb %in% worstfit$Suburb)
ggplot(data=mh_u_sub, aes(x=Date, y=Price)) + 
         geom_point() + geom_smooth(method="lm", se=FALSE) +
  facet_wrap(~Suburb, ncol=3)
mh_u_sub <- mh_u %>% filter(Suburb %in% c("Malvern", "Malvern East"))
ggplot(data=mh_u_sub, aes(x=Date, y=Price)) + 
         geom_point() + geom_smooth(method="lm", se=FALSE) +
  facet_wrap(~Suburb, ncol=2)

```

4. Examine the results of the auctions, with the Method variable, across suburbs. Perhaps compute proportion of PI, NB, VB, W, relative to the rest of the categories, by month over the years. The goal here is to determine if the downturn might be indicated by a higher proportion of unsold properties. 

5. Fit a big model!

# Grading

Points for the assignment will be based on:

- Accuracy of your answers to the given questions. 
- How well you have conducted the analysis, and written your answers. 
- Whether the Rmd file, can take data file as provided, produce the tidy data, and plots reported in your final submission.
- How well you have worked with your group members on completing this work. Your score for the group component will be adjusted by the amount of effort your team mates independently and anonymously report. 
